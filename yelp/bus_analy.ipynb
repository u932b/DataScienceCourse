{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %ls yelp_dataset\n",
    "# % pwd\n",
    "# input_dir = \"/Users/chenghsi/chchao/NYU/DataScienceCourse/yelp/\"\n",
    "input_dir = \"/home/ubuntu/chchao/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USERPATH = input_dir + \"yelp_dataset/yelp_academic_dataset_user.json\"\n",
    "REVIEWPATH = input_dir + \"yelp_dataset/yelp_academic_dataset_review.csv\"\n",
    "TOR_BUS_PATH = input_dir + \"yelp_dataset/yelp_toronto_business.pickle\"\n",
    "VEGAS_BUS_PATH = input_dir + \"yelp_dataset/yelp_vegas_business.pickle\"\n",
    "MONTREAL_BUS_PATH = input_dir + \"yelp_dataset/yelp_montreal_business.pickle\"\n",
    "PHOENIX_BUS_PATH = input_dir + \"yelp_dataset/yelp_phoenix_business.pickle\"\n",
    "BUS_PATH = input_dir + \"yelp_dataset/yelp_academic_dataset_business.pickle\"\n",
    "PROCCESSED_BUS_PATH = input_dir + \"yelp_dataset/df_convert/yelp_academic_dataset_business.pickle\"\n",
    "CITY_LIST = input_dir + \"city_cnt_list\"\n",
    "STATE_LIST = input_dir + \"state_cnt_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_to_df(pickle_path, verbose=False):\n",
    "    serial_pickle = pd.read_pickle(pickle_path)\n",
    "    df = pd.DataFrame.from_dict(serial_pickle, orient='index')\n",
    "    features = []\n",
    "    bool_map = {'True': True,'False': False}\n",
    "    if \"business\" in pickle_path:\n",
    "        # print (df.columns.values)\n",
    "        columns_to_exclude = ['business_id', 'name', 'address', 'is_open']\n",
    "        # df = df [[df.columns.values]]\n",
    "        # df = df[['categories', 'review_count', 'stars', 'is_open', 'attributes', 'postal_code']]\n",
    "        df = df[df['categories'].notnull()] # drop row with null categories\n",
    "        df = df[df['categories'].str.contains('Restaurant')] # select only rows with restaurant as categories\n",
    "        la_list = ['stars', 'review_count', 'Ambience_romantic', 'Ambience_intimate', 'Ambience_classy',\n",
    " 'Ambience_hipster', 'Ambience_touristy', 'Ambience_trendy',\n",
    " 'Ambience_upscale', 'Ambience_casual', 'BikeParking', 'BusinessAcceptsCreditCards', 'BusinessParking_garage',\n",
    " 'BusinessParking_street', 'BusinessParking_validated', 'BusinessParking_lot',\n",
    " 'BusinessParking_valet', 'Caters', 'GoodForKids', 'GoodForMeal_dessert',\n",
    " 'GoodForMeal_latenight', 'GoodForMeal_lunch', 'GoodForMeal_dinner',\n",
    " 'GoodForMeal_breakfast', 'GoodForMeal_brunch', 'HasTV', 'OutdoorSeating', 'RestaurantsDelivery',\n",
    " 'RestaurantsGoodForGroups', 'RestaurantsReservations', 'RestaurantsTableService', 'RestaurantsTakeOut', 'Music_dj', 'Music_background_music', 'Music_no_music', 'Music_karaoke',\n",
    " 'Music_live', 'Music_video', 'Music_jukebox', 'DogsAllowed', 'Open24Hours', 'RestaurantsCounterService']\n",
    "        # for col in la_list:\n",
    "        for col in df.columns.values:\n",
    "            df[col].map(bool_map)\n",
    "        \n",
    "        \n",
    "        for feature in df.columns:       \n",
    "            # if feature not in columns_to_exclude:\n",
    "            if feature in la_list:\n",
    "                features.append(feature)\n",
    "        \n",
    "        # store the df as pickle for use\n",
    "        df.to_pickle(input_dir + \"yelp_dataset/df_convert/\" + pickle_path.split('/')[-1])\n",
    "        return df[features].fillna(-1), df[[\"is_open\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_target_seperator(df):\n",
    "    features = []\n",
    "    la_list = ['stars', 'review_count', 'Ambience_romantic', 'Ambience_intimate', 'Ambience_classy',\n",
    " 'Ambience_hipster', 'Ambience_touristy', 'Ambience_trendy',\n",
    " 'Ambience_upscale', 'Ambience_casual', 'BikeParking', 'BusinessAcceptsCreditCards', 'BusinessParking_garage',\n",
    " 'BusinessParking_street', 'BusinessParking_validated', 'BusinessParking_lot',\n",
    " 'BusinessParking_valet', 'Caters', 'GoodForKids', 'GoodForMeal_dessert',\n",
    " 'GoodForMeal_latenight', 'GoodForMeal_lunch', 'GoodForMeal_dinner',\n",
    " 'GoodForMeal_breakfast', 'GoodForMeal_brunch', 'HasTV', 'OutdoorSeating', 'RestaurantsDelivery',\n",
    " 'RestaurantsGoodForGroups', 'RestaurantsReservations', 'RestaurantsTableService', 'RestaurantsTakeOut', 'Music_dj', 'Music_background_music', 'Music_no_music', 'Music_karaoke',\n",
    " 'Music_live', 'Music_video', 'Music_jukebox', 'DogsAllowed', 'Open24Hours', 'RestaurantsCounterService']\n",
    "    for feature in df.columns:       \n",
    "        # if feature not in columns_to_exclude:\n",
    "        if feature in la_list:\n",
    "            features.append(feature)\n",
    "    return df[features].fillna(-1), df[[\"is_open\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file, verbose=False):\n",
    "    df = pd.DataFrame.from_csv(csv_file, index_col=2)\n",
    "    features = []\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print (\"columns in csv:\\n\", list(df))\n",
    "        print (\"Rows with null values:\\n\", df.isnull().sum())\n",
    "        print (\"is_open counts for csv:\\n\", df['is_open'].value_counts())\n",
    "\n",
    "    if \"business\" in csv_file:\n",
    "        df = df[['categories', 'review_count', 'stars', 'is_open', 'attributes', 'postal_code']]\n",
    "        df = df[df['categories'].notnull()] # drop row with null categories\n",
    "        df = df[df['categories'].str.contains('Restaurant')] # select only rows with restaurant as categories\n",
    "        \n",
    "        for feature in df.columns:       \n",
    "            if feature != \"is_open\" and feature != \"categories\":\n",
    "                features.append(feature)\n",
    "    \n",
    "        return df[features], df[[\"is_open\"]]\n",
    "    \n",
    "    if \"review\" in csv_file:\n",
    "        print (list(df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX, Y = csv_to_df(TOR_BUS_PATH)\\nfoo = lambda X: pd.Series([i for i in reversed(X.split(','))])\\nprint (foo)\\nrev = X.apply(foo)\\nprint (rev)\\nprint (X['attributes'].head())\\n# print (X.index)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X, Y = csv_to_df(TOR_BUS_PATH)\n",
    "foo = lambda X: pd.Series([i for i in reversed(X.split(','))])\n",
    "print (foo)\n",
    "rev = X.apply(foo)\n",
    "print (rev)\n",
    "print (X['attributes'].head())\n",
    "# print (X.index)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df = pd.read_pickle(file_name)\n",
    "X, Y = pickle_to_df(BUS_PATH)\n",
    "# print (X, Y.transpose().values[0])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spl_list = [2**x for x in range(1,10)]\n",
    "depth_list = [x for x in range(1,32)]\n",
    "min_sample_list = [2**x for x in range(0,10)]\n",
    "class_weight_list = [None, \"balanced\"]\n",
    "\n",
    "tree_param = {'min_samples_split':spl_list, 'max_depth':depth_list, 'min_samples_leaf':min_sample_list, 'class_weight':class_weight_list}\n",
    "tree = GridSearchCV(DecisionTreeClassifier(criterion=\"entropy\"), tree_param)\n",
    "tree.fit(X, Y.transpose().values[0])\n",
    "\n",
    "print(tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(max_depth=14, min_samples_leaf=32, criterion=\"entropy\",min_samples_split=256, class_weight=None)\n",
    "tree_model.fit(X_train, Y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "\n",
    "svm_model.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83709996700758826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117942283563363"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.817954\n",
      "Accuracy on test = 0.811794\n",
      "Accuracy on Vegas = 0.701638\n",
      "Accuracy on Phoenix = 0.811737\n",
      "Accuracy on All = 0.757594\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn   # This library will help to get the values\n",
    "from sklearn import metrics\n",
    "\n",
    "# print (X)\n",
    "tree_data_accuracy =\\\n",
    "print ( \"Accuracy on training = %.6f\" % metrics.accuracy_score(tree_model.predict(X_train), Y_train) )\n",
    "print ( \"Accuracy on test = %.6f\" % metrics.accuracy_score(tree_model.predict(X_test), Y_test) )\n",
    "\n",
    "vegas_X, vegas_Y = pickle_to_df(VEGAS_BUS_PATH)\n",
    "print ( \"Accuracy on Vegas = %.6f\" % metrics.accuracy_score(tree_model.predict(vegas_X), vegas_Y) )\n",
    "\n",
    "pho_X, pho_Y = pickle_to_df(PHOENIX_BUS_PATH)\n",
    "print ( \"Accuracy on Phoenix = %.6f\" % metrics.accuracy_score(tree_model.predict(pho_X), pho_Y) )\n",
    "\n",
    "# mon_X, mon_Y = pickle_to_df(MONTREAL_BUS_PATH)\n",
    "# print ( \"Accuracy on Montreal = %.6f\" % metrics.accuracy_score(tree_model.predict(mon_X), mon_Y) )\n",
    "\n",
    "bus_X, bus_Y = pickle_to_df(BUS_PATH)\n",
    "print ( \"Accuracy on All = %.6f\" % metrics.accuracy_score(tree_model.predict(bus_X), bus_Y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.836042\n",
      "Accuracy on test = 0.837100\n",
      "Accuracy on Vegas = 0.708264\n",
      "Accuracy on Phoenix = 0.735478\n",
      "Accuracy on Montreal = 0.709556\n",
      "Accuracy on All = 0.836306\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn   # This library will help to get the values\n",
    "from sklearn import metrics\n",
    "\n",
    "# print (X)\n",
    "tree_data_accuracy =\\\n",
    "print ( \"Accuracy on training = %.6f\" % metrics.accuracy_score(svm_model.predict(X_train), Y_train) )\n",
    "print ( \"Accuracy on test = %.6f\" % metrics.accuracy_score(svm_model.predict(X_test), Y_test) )\n",
    "\n",
    "vegas_X, vegas_Y = pickle_to_df(VEGAS_BUS_PATH)\n",
    "print ( \"Accuracy on Vegas = %.6f\" % metrics.accuracy_score(svm_model.predict(vegas_X), vegas_Y) )\n",
    "\n",
    "pho_X, pho_Y = pickle_to_df(PHOENIX_BUS_PATH)\n",
    "print ( \"Accuracy on Phoenix = %.6f\" % metrics.accuracy_score(svm_model.predict(pho_X), pho_Y) )\n",
    "\n",
    "# mon_X, mon_Y = pickle_to_df(MONTREAL_BUS_PATH)\n",
    "# print ( \"Accuracy on Montreal = %.6f\" % metrics.accuracy_score(svm_model.predict(mon_X), mon_Y) )\n",
    "\n",
    "tor_X, tor_Y = pickle_to_df(TOR_BUS_PATH)\n",
    "print ( \"Accuracy on Montreal = %.6f\" % metrics.accuracy_score(svm_model.predict(tor_X), tor_Y) )\n",
    "\n",
    "bus_X, bus_Y = pickle_to_df(BUS_PATH)\n",
    "print ( \"Accuracy on All = %.6f\" % metrics.accuracy_score(svm_model.predict(bus_X), bus_Y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the count TRAIN data = 0.799\n",
      "AUC on the count TEST data = 0.790\n"
     ]
    }
   ],
   "source": [
    "print (\"AUC on the count TRAIN data = %.3f\" % metrics.roc_auc_score(tree_model.predict(X_train), Y_train))\n",
    "print (\"AUC on the count TEST data = %.3f\" % metrics.roc_auc_score(tree_model.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_to_df(REVIEWPATH) # huge memory hit...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 264, True: 1330}\n",
      "      p    n\n",
      "Y  1104  226\n",
      "N    65  199\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "probabilities = tree_model.predict_proba(X_test)[:, 1]\n",
    "prediction = probabilities > 0.5\n",
    "# print (prediction)\n",
    "unique, counts = numpy.unique(prediction, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "\n",
    "confusion_matrix_large = pd.DataFrame(metrics.confusion_matrix(Y_test, prediction, labels=[1, 0]).T,\n",
    "                                columns=['p', 'n'], index=['Y', 'N'])\n",
    "print (confusion_matrix_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7245922208281054\n"
     ]
    }
   ],
   "source": [
    "print (1155/(1155+439))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 786, True: 3993}\n",
      "      p    n\n",
      "Y  3294  699\n",
      "N   174  612\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "probabilities = tree_model.predict_proba(X_train)[:, 1]\n",
    "prediction = probabilities > 0.5\n",
    "# print (prediction)\n",
    "unique, counts = numpy.unique(prediction, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "\n",
    "confusion_matrix_large = pd.DataFrame(metrics.confusion_matrix(Y_train, prediction, labels=[1, 0]).T,\n",
    "                                columns=['p', 'n'], index=['Y', 'N'])\n",
    "print (confusion_matrix_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7286043105252145\n"
     ]
    }
   ],
   "source": [
    "print (3482/(3482+1297))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(PROCCESSED_BUS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>...</th>\n",
       "      <th>Music_background_music</th>\n",
       "      <th>Music_no_music</th>\n",
       "      <th>Music_karaoke</th>\n",
       "      <th>Music_live</th>\n",
       "      <th>Music_video</th>\n",
       "      <th>Music_jukebox</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AgesAllowed</th>\n",
       "      <th>DietaryRestrictions</th>\n",
       "      <th>Open24Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>John's Chinese BBQ Restaurant</td>\n",
       "      <td></td>\n",
       "      <td>328 Highway 7 E, Chalmers Gate 11, Unit 10</td>\n",
       "      <td>Richmond Hill</td>\n",
       "      <td>ON</td>\n",
       "      <td>L4B 3P7</td>\n",
       "      <td>43.840905</td>\n",
       "      <td>-79.399604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>The Strip</td>\n",
       "      <td>3355 Las Vegas Blvd S</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89109</td>\n",
       "      <td>36.123183</td>\n",
       "      <td>-115.169190</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DaPTJW3-tB1vP-PfdTEg</th>\n",
       "      <td>--DaPTJW3-tB1vP-PfdTEg</td>\n",
       "      <td>Sunnyside Grill</td>\n",
       "      <td>Corso Italia</td>\n",
       "      <td>1218 Saint Clair Avenue W</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>M6E</td>\n",
       "      <td>43.677807</td>\n",
       "      <td>-79.444674</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--FBCX-N37CMYDfs790Bnw</th>\n",
       "      <td>--FBCX-N37CMYDfs790Bnw</td>\n",
       "      <td>The Bar At Bermuda &amp; St. Rose</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>11624 Bermuda Rd</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>89052</td>\n",
       "      <td>35.978689</td>\n",
       "      <td>-115.155016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--GM_ORV2cYS-h38DSaCLw</th>\n",
       "      <td>--GM_ORV2cYS-h38DSaCLw</td>\n",
       "      <td>Mm Mm Pizza</td>\n",
       "      <td></td>\n",
       "      <td>407 S Central Ave</td>\n",
       "      <td>Canonsburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>15317</td>\n",
       "      <td>40.252569</td>\n",
       "      <td>-80.183859</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   business_id                           name  \\\n",
       "--6MefnULPED_I942VcFNA  --6MefnULPED_I942VcFNA  John's Chinese BBQ Restaurant   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  --9e1ONYQuAa-CB_Rrw7Tw           Delmonico Steakhouse   \n",
       "--DaPTJW3-tB1vP-PfdTEg  --DaPTJW3-tB1vP-PfdTEg                Sunnyside Grill   \n",
       "--FBCX-N37CMYDfs790Bnw  --FBCX-N37CMYDfs790Bnw  The Bar At Bermuda & St. Rose   \n",
       "--GM_ORV2cYS-h38DSaCLw  --GM_ORV2cYS-h38DSaCLw                    Mm Mm Pizza   \n",
       "\n",
       "                        neighborhood  \\\n",
       "--6MefnULPED_I942VcFNA                 \n",
       "--9e1ONYQuAa-CB_Rrw7Tw     The Strip   \n",
       "--DaPTJW3-tB1vP-PfdTEg  Corso Italia   \n",
       "--FBCX-N37CMYDfs790Bnw     Southeast   \n",
       "--GM_ORV2cYS-h38DSaCLw                 \n",
       "\n",
       "                                                           address  \\\n",
       "--6MefnULPED_I942VcFNA  328 Highway 7 E, Chalmers Gate 11, Unit 10   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw                       3355 Las Vegas Blvd S   \n",
       "--DaPTJW3-tB1vP-PfdTEg                   1218 Saint Clair Avenue W   \n",
       "--FBCX-N37CMYDfs790Bnw                            11624 Bermuda Rd   \n",
       "--GM_ORV2cYS-h38DSaCLw                           407 S Central Ave   \n",
       "\n",
       "                                 city state postal_code   latitude  \\\n",
       "--6MefnULPED_I942VcFNA  Richmond Hill    ON     L4B 3P7  43.840905   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw      Las Vegas    NV       89109  36.123183   \n",
       "--DaPTJW3-tB1vP-PfdTEg        Toronto    ON         M6E  43.677807   \n",
       "--FBCX-N37CMYDfs790Bnw      Henderson    NV       89052  35.978689   \n",
       "--GM_ORV2cYS-h38DSaCLw     Canonsburg    PA       15317  40.252569   \n",
       "\n",
       "                         longitude  stars     ...      Music_background_music  \\\n",
       "--6MefnULPED_I942VcFNA  -79.399604    3.0     ...                         NaN   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw -115.169190    4.0     ...                         NaN   \n",
       "--DaPTJW3-tB1vP-PfdTEg  -79.444674    3.5     ...                         NaN   \n",
       "--FBCX-N37CMYDfs790Bnw -115.155016    4.0     ...                       False   \n",
       "--GM_ORV2cYS-h38DSaCLw  -80.183859    3.5     ...                         NaN   \n",
       "\n",
       "                        Music_no_music Music_karaoke Music_live Music_video  \\\n",
       "--6MefnULPED_I942VcFNA             NaN           NaN        NaN         NaN   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw             NaN           NaN        NaN         NaN   \n",
       "--DaPTJW3-tB1vP-PfdTEg             NaN           NaN        NaN         NaN   \n",
       "--FBCX-N37CMYDfs790Bnw           False         False      False       False   \n",
       "--GM_ORV2cYS-h38DSaCLw             NaN           NaN        NaN         NaN   \n",
       "\n",
       "                       Music_jukebox Smoking AgesAllowed DietaryRestrictions  \\\n",
       "--6MefnULPED_I942VcFNA           NaN     NaN         NaN                 NaN   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw           NaN     NaN         NaN                 NaN   \n",
       "--DaPTJW3-tB1vP-PfdTEg           NaN     NaN         NaN                 NaN   \n",
       "--FBCX-N37CMYDfs790Bnw         False     NaN         NaN                 NaN   \n",
       "--GM_ORV2cYS-h38DSaCLw           NaN     NaN         NaN                 NaN   \n",
       "\n",
       "                       Open24Hours  \n",
       "--6MefnULPED_I942VcFNA         NaN  \n",
       "--9e1ONYQuAa-CB_Rrw7Tw       False  \n",
       "--DaPTJW3-tB1vP-PfdTEg         NaN  \n",
       "--FBCX-N37CMYDfs790Bnw         NaN  \n",
       "--GM_ORV2cYS-h38DSaCLw         NaN  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NV', 'ON', 'AZ', 'NC', 'PA', 'QC', 'EDH', 'OH', 'WI', 'BW', 'IL', 'SC'])\n"
     ]
    }
   ],
   "source": [
    "state_dfs = {} \n",
    "with open(CITY_LIST, 'r') as city_list:\n",
    "    for line in city_list:\n",
    "        city = line.split('|')[0].strip()\n",
    "        state = line.split('|')[1].strip()\n",
    "        count = line.split('|')[2].strip()\n",
    "        city_df = df.loc[df['city'] == city]\n",
    "        city_df.to_pickle(input_dir + \"yelp_dataset/df_convert/\" + state + \"_\" + city + \".pickle\")\n",
    "        try:\n",
    "            type(state_dfs[state])\n",
    "        except:\n",
    "            state_dfs[state] = {}\n",
    "        state_dfs[state][city] = city_df\n",
    "print (state_dfs.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AZ', 'NV', 'ON', 'NC', 'OH', 'PA', 'QC', 'WI', 'EDH', 'BW', 'IL', 'SC', 'MLN', 'HLD'])\n"
     ]
    }
   ],
   "source": [
    "just_state_dfs = {}\n",
    "with open(STATE_LIST, 'r') as state_list:\n",
    "    for line in state_list:\n",
    "        state = line.split('|')[0].strip()\n",
    "        count = line.split('|')[1].strip()\n",
    "        just_state_df = df.loc[df['state'] == state]\n",
    "        # city_df.to_pickle(input_dir + \"yelp_dataset/df_convert/\" + state + \"_\" + city + \".pickle\")\n",
    "        # try:\n",
    "        #     type(just_state_dfs[state])\n",
    "        # except:\n",
    "        #     just_state_dfs[state] = {}\n",
    "        if int(count) > 100:\n",
    "            just_state_dfs[state] = just_state_df\n",
    "print (just_state_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def create_svm_model(df, gridcv=false):\n",
    "    X, Y = feature_target_seperator(df)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.75)\n",
    "\n",
    "    svm_model = svm.SVC(kernel='linear')\n",
    "    # svm_model = svm.SVC(C=10, gamma=0.001, kernel='rbf', probability=True)\n",
    "    svm_model.fit(X_train, Y_train.values.ravel())\n",
    "    print ( \"Accuracy on training = %.6f\" % metrics.accuracy_score(svm_model.predict(X_train), Y_train) )\n",
    "    print ( \"Accuracy on test = %.6f\" % metrics.accuracy_score(svm_model.predict(X_test), Y_test) )\n",
    "    \n",
    "    # predicted = cross_val_predict(svm_model, X, Y, cv=10)\n",
    "    # print ( \"cross validation score = %.6f\" % metrics.accuracy_score(Y, predicted))\n",
    "\n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaulate_model_by_state(svm_model, state):\n",
    "    for city in state_dfs[state].keys():\n",
    "        test_X, test_Y = feature_target_seperator(state_dfs[state][city])\n",
    "        print ( \"Accuracy on %s = %.6f\" % (city, metrics.accuracy_score(svm_model.predict(test_X), test_Y) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaulate_model_by_state(svm_model, state):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaulate_model_against_all(svm_model):\n",
    "    bus_df = pd.read_pickle(PROCCESSED_BUS_PATH)\n",
    "    test_X, test_Y = feature_target_seperator(bus_df)\n",
    "    print ( \"Accuracy on total = %.6f\" % (metrics.accuracy_score(svm_model.predict(test_X), test_Y) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model for AZ\n",
      "Accuracy on training = 0.861047\n",
      "Accuracy on test = 0.851230\n",
      "Creating model for NV\n",
      "Accuracy on training = 0.834853\n",
      "Accuracy on test = 0.825638\n",
      "Creating model for ON\n",
      "Accuracy on training = 0.827979\n",
      "Accuracy on test = 0.826042\n",
      "Creating model for NC\n",
      "Accuracy on training = 0.874310\n",
      "Accuracy on test = 0.853428\n",
      "Creating model for OH\n",
      "Accuracy on training = 0.844465\n",
      "Accuracy on test = 0.841016\n",
      "Creating model for PA\n",
      "Accuracy on training = 0.846600\n",
      "Accuracy on test = 0.833540\n",
      "Creating model for QC\n",
      "Accuracy on training = 0.832641\n",
      "Accuracy on test = 0.823755\n",
      "Creating model for WI\n",
      "Accuracy on training = 0.848859\n",
      "Accuracy on test = 0.823362\n",
      "Creating model for EDH\n",
      "Accuracy on training = 0.752907\n",
      "Accuracy on test = 0.773256\n",
      "Creating model for BW\n",
      "Accuracy on training = 0.875505\n",
      "Accuracy on test = 0.861985\n",
      "Creating model for IL\n",
      "Accuracy on training = 0.818396\n",
      "Accuracy on test = 0.809859\n",
      "Creating model for SC\n",
      "Accuracy on training = 0.746377\n",
      "Accuracy on test = 0.695652\n",
      "Creating model for MLN\n",
      "Accuracy on training = 0.811594\n",
      "Accuracy on test = 0.791667\n",
      "Creating model for HLD\n",
      "Accuracy on training = 0.928571\n",
      "Accuracy on test = 1.000000\n"
     ]
    }
   ],
   "source": [
    "state_models = {}\n",
    "for state_df in just_state_dfs.keys():\n",
    "    print (\"Creating model for %s\" %(state_df))\n",
    "    state_models[state_df] = create_svm_model(just_state_dfs[state_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for state_models in state_models.keys():\n",
    "    for state_df in just_state_dfs.keys():\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.852205\n",
      "Accuracy on test = 0.863095\n"
     ]
    }
   ],
   "source": [
    "Phoenix_svm_model = create_svm_model(state_dfs['AZ']['Phoenix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Phoenix = 0.855228\n",
      "Accuracy on Scottsdale = 0.840708\n",
      "Accuracy on Mesa = 0.885548\n",
      "Accuracy on Tempe = 0.848485\n",
      "Accuracy on Chandler = 0.835106\n",
      "Accuracy on Gilbert = 0.867804\n",
      "Accuracy on Glendale = 0.865353\n",
      "Accuracy on Peoria = 0.891026\n",
      "Accuracy on Surprise = 0.875000\n",
      "Accuracy on Goodyear = 0.899371\n",
      "Accuracy on Avondale = 0.895425\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_by_state(svm_model, 'AZ')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on total = 0.805085\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_against_all(Phoenix_svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.811345\n",
      "Accuracy on test = 0.795841\n"
     ]
    }
   ],
   "source": [
    "Toronto_svm_model = create_svm_model(state_dfs['ON']['Toronto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.813025\n",
      "Accuracy on test = 0.806553\n"
     ]
    }
   ],
   "source": [
    "Toronto_svm_model2 = create_svm_model(state_dfs['ON']['Toronto']) # using charlottes's attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Toronto = 0.806050\n",
      "Accuracy on Mississauga = 0.857270\n",
      "Accuracy on Markham = 0.835843\n",
      "Accuracy on North York = 0.809019\n",
      "Accuracy on Scarborough = 0.837772\n",
      "Accuracy on Richmond Hill = 0.796069\n",
      "Accuracy on Brampton = 0.823383\n",
      "Accuracy on Vaughan = 0.839888\n",
      "Accuracy on Etobicoke = 0.836735\n",
      "Accuracy on Oakville = 0.837545\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_by_state(svm_model, 'ON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on total = 0.817603\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_against_all(Toronto_svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.874621\n",
      "Accuracy on test = 0.852995\n"
     ]
    }
   ],
   "source": [
    "Charlotte_svm_model = create_svm_model(state_dfs['NC']['Charlotte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Charlotte = 0.876930\n",
      "Accuracy on Concord = 0.861004\n",
      "Accuracy on Matthews = 0.843023\n",
      "Accuracy on Huntersville = 0.945312\n",
      "Accuracy on Cornelius = 0.839080\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_by_state(svm_model, 'NC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on total = 0.815210\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_against_all(Charlotte_svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Las Vegas = 0.819805\n",
      "Accuracy on Henderson = 0.842653\n",
      "Accuracy on North Las Vegas = 0.853242\n",
      "Accuracy on Toronto = 0.801166\n",
      "Accuracy on Mississauga = 0.853723\n",
      "Accuracy on Markham = 0.813253\n",
      "Accuracy on North York = 0.811671\n",
      "Accuracy on Scarborough = 0.847458\n",
      "Accuracy on Richmond Hill = 0.773956\n",
      "Accuracy on Brampton = 0.820896\n",
      "Accuracy on Vaughan = 0.828652\n",
      "Accuracy on Etobicoke = 0.836735\n",
      "Accuracy on Oakville = 0.844765\n",
      "Accuracy on Phoenix = 0.850760\n",
      "Accuracy on Scottsdale = 0.822271\n",
      "Accuracy on Mesa = 0.875849\n",
      "Accuracy on Tempe = 0.838384\n",
      "Accuracy on Chandler = 0.832447\n",
      "Accuracy on Gilbert = 0.855011\n",
      "Accuracy on Glendale = 0.858785\n",
      "Accuracy on Peoria = 0.897436\n",
      "Accuracy on Surprise = 0.864583\n",
      "Accuracy on Goodyear = 0.886792\n",
      "Accuracy on Avondale = 0.901961\n",
      "Accuracy on Charlotte = 0.869210\n",
      "Accuracy on Concord = 0.868726\n",
      "Accuracy on Matthews = 0.831395\n",
      "Accuracy on Huntersville = 0.937500\n",
      "Accuracy on Cornelius = 0.850575\n",
      "Accuracy on Pittsburgh = 0.837688\n",
      "Accuracy on Montréal = 0.787518\n",
      "Accuracy on Edinburgh = 0.716006\n",
      "Accuracy on Cleveland = 0.824291\n",
      "Accuracy on Lakewood = 0.823529\n",
      "Accuracy on Mentor = 0.850340\n",
      "Accuracy on Madison = 0.828694\n",
      "Accuracy on Stuttgart = 0.562622\n",
      "Accuracy on Champaign = 0.817927\n",
      "Accuracy on Urbana = 0.884956\n",
      "Accuracy on Fort Mill = 0.798658\n"
     ]
    }
   ],
   "source": [
    "for state in state_dfs.keys():\n",
    "    evaulate_model_by_state(Charlotte_svm_model, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.837015\n",
      "Accuracy on test = 0.844003\n"
     ]
    }
   ],
   "source": [
    "Vegas_svm_model = create_svm_model(state_dfs['NV']['Las Vegas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Las Vegas = 0.828824\n",
      "Accuracy on Henderson = 0.845254\n",
      "Accuracy on North Las Vegas = 0.866894\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_by_state(svm_model, 'NV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on total = 0.791578\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_against_all(Vegas_svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.387 (+/-0.001) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.387 (+/-0.001) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.865 (+/-0.061) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.387 (+/-0.001) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.827 (+/-0.071) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.853 (+/-0.054) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.067) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.826 (+/-0.069) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.839 (+/-0.053) for {'C': 1, 'kernel': 'linear'}\n",
      "0.843 (+/-0.052) for {'C': 10, 'kernel': 'linear'}\n",
      "0.836 (+/-0.043) for {'C': 100, 'kernel': 'linear'}\n",
      "0.833 (+/-0.043) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-3367febf9e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The scores are computed on the full evaluation set.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X, Y = feature_target_seperator(state_dfs['NC']['Charlotte'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.5)\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.49      0.61       251\n",
      "          1       0.86      0.96      0.91       850\n",
      "\n",
      "avg / total       0.85      0.86      0.84      1101\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training = 0.869776\n",
      "Accuracy on test = 0.874773\n"
     ]
    }
   ],
   "source": [
    "Charlotte_svm_model = create_svm_model(state_dfs['NC']['Charlotte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on total = 0.817438\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_against_all(Charlotte_svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Charlotte = 0.876930\n",
      "Accuracy on Concord = 0.861004\n",
      "Accuracy on Matthews = 0.843023\n",
      "Accuracy on Huntersville = 0.945312\n",
      "Accuracy on Cornelius = 0.839080\n"
     ]
    }
   ],
   "source": [
    "evaulate_model_by_state(svm_model, 'NC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 177, True: 924}\n",
      "     p    n\n",
      "Y  815  109\n",
      "N   37  140\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "probabilities = Toronto_svm_model2.predict_proba(X_train)[:, 1]\n",
    "prediction = probabilities > 0.5\n",
    "# print (prediction)\n",
    "unique, counts = numpy.unique(prediction, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "\n",
    "confusion_matrix_large = pd.DataFrame(metrics.confusion_matrix(Y_train, prediction, labels=[1, 0]).T,\n",
    "                                    columns=['p', 'n'], index=['Y', 'N'])\n",
    "\n",
    "print (confusion_matrix_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve on test data = 0.756 (SVM)\n"
     ]
    }
   ],
   "source": [
    "# X, Y = feature_target_seperator(state_dfs['NV']['Las Vegas'])\n",
    "X, Y = feature_target_seperator(state_dfs['NC']['Charlotte'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.75)\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "# svm_model = svm.SVC(C=10, gamma=0.001, kernel='rbf', probability=True)\n",
    "svm_model.fit(X_train, Y_train.values.ravel())\n",
    "print (\"Area under the ROC curve on test data = %.3f (SVM)\" % metrics.roc_auc_score(Y_test, svm_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
